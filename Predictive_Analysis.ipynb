{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y2a65TE7deqa",
        "outputId": "f298321d-5d77-44d6-8f84-0da1a813c05b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.46.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading starlette-0.45.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, pyngrok, starlette, fastapi\n",
            "Successfully installed fastapi-0.115.7 pyngrok-7.2.3 starlette-0.45.2 uvicorn-0.34.0\n",
            "Collecting python-multipart\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: python-multipart\n",
            "Successfully installed python-multipart-0.0.20\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi uvicorn pyngrok  pandas\n",
        "!pip install python-multipart\n",
        "!pip install scikit-learn==1.3.0\n",
        "!pip install imbalanced-learn==0.11.0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, File, UploadFile\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "app = FastAPI(debug=True)\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def read_root():\n",
        "    logger.info(\"Root endpoint accessed\")\n",
        "    return {\"message\": \"Welcome to the Machine Downtime Prediction API!\"}\n",
        "\n",
        "@app.post(\"/upload/\")\n",
        "async def upload_file(file: UploadFile = File(...)):\n",
        "    logger.info(f\"Upload endpoint accessed with file: {file.filename}\")\n",
        "    try:\n",
        "        global dataset\n",
        "        contents = await file.read()\n",
        "        with open('temp.csv', 'wb') as f:\n",
        "            f.write(contents)\n",
        "        dataset = pd.read_csv('temp.csv')\n",
        "\n",
        "        return {\n",
        "            \"message\": f\"File '{file.filename}' uploaded successfully\",\n",
        "            \"columns\": dataset.columns.tolist()\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing upload: {str(e)}\")\n",
        "        return {\"error\": str(e)}"
      ],
      "metadata": {
        "id": "PWkyedLsdkpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate synthetic data\n",
        "num_records = 1000\n",
        "data = {\n",
        "    \"Machine_ID\": np.random.randint(1, 21, num_records),  # 20 unique machine IDs\n",
        "    \"Temperature\": np.random.uniform(50, 100, num_records),  # Random temperatures between 50 and 100\n",
        "    \"Run_Time\": np.random.uniform(1, 1000, num_records),  # Random run times between 1 and 1000 hours\n",
        "    \"Downtime_Flag\": np.random.choice([0, 1], num_records, p=[0.7, 0.3])  # 70% No downtime, 30% downtime\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "file_name = \"machine_downtime.csv\"\n",
        "df.to_csv(file_name, index=False)\n",
        "\n",
        "print(f\"Synthetic data saved as '{file_name}'\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rXNeXtgeM37",
        "outputId": "3f7f5b78-87ae-46e1-cf36-f8c42ff0ead5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic data saved as 'machine_downtime.csv'\n",
            "   Machine_ID  Temperature    Run_Time  Downtime_Flag\n",
            "0           7    73.285006  895.918783              1\n",
            "1          20    74.041849  322.893288              0\n",
            "2          15    95.922736  126.108337              0\n",
            "3          11    79.353411  474.861774              0\n",
            "4           8    51.642334  114.842678              1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import threading\n",
        "import time\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "ngrok.kill()\n",
        "\n",
        "ngrok.set_auth_token(\"<YOUR_NGROK_TOKEN>\")\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "public_url = ngrok_tunnel.public_url\n",
        "print('Public URL:', public_url)\n",
        "\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "time.sleep(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu_aAIIcdzGC",
        "outputId": "d5bb9a72-d9fc-4991-ce90-531947af0939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://229f-34-139-187-100.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [575]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     223.233.86.126:0 - \"GET / HTTP/1.1\" 200 OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"<YOUR_NGROK_PUBLIC_URL>/upload/\"  # Replace <YOUR_NGROK_PUBLIC_URL> with your actual ngrok URL\n",
        "files = {\"file\": open(\"machine_downtime.csv\", \"rb\")}\n",
        "response = requests.post(url, files=files)\n",
        "\n",
        "print(response.json())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVRUq7woyWst",
        "outputId": "d361a35d-a5d0-4759-df4b-a77430cae039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     34.139.187.100:0 - \"POST /upload/ HTTP/1.1\" 200 OK\n",
            "{'message': \"File 'machine_downtime.csv' uploaded successfully\", 'columns': ['Machine_ID', 'Temperature', 'Run_Time', 'Downtime_Flag']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "import joblib\n",
        "from fastapi import HTTPException"
      ],
      "metadata": {
        "id": "BQPuZZL1ksak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "\n",
        "scaler = StandardScaler()\n",
        "@app.post(\"/train\")\n",
        "async def train_model():\n",
        "    try:\n",
        "        global dataset, model, scaler\n",
        "\n",
        "        if dataset is None:\n",
        "            return {\"error\": \"No dataset uploaded. Please upload dataset first.\"}\n",
        "\n",
        "        X = dataset[[\"Temperature\", \"Run_Time\"]]\n",
        "        y = dataset[\"Downtime_Flag\"]\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_train_resampled, y_train_resampled = smote.fit_resample(\n",
        "            X_train_scaled, y_train\n",
        "        )\n",
        "\n",
        "        model = LogisticRegression(\n",
        "            C=1.0,\n",
        "            penalty='l2',\n",
        "            solver='lbfgs',\n",
        "            max_iter=1000,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        metrics = {\n",
        "            \"accuracy\": np.round(accuracy_score(y_test, y_pred), 3),\n",
        "            \"f1_score\": np.round(f1_score(y_test, y_pred), 3),\n",
        "            \"precision\": np.round(precision_score(y_test, y_pred), 3),\n",
        "            \"recall\": np.round(recall_score(y_test, y_pred), 3)\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"message\": \"Model trained successfully\",\n",
        "            **metrics\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error training model: {str(e)}\")\n",
        "        return {\"error\": str(e)}"
      ],
      "metadata": {
        "id": "f7r9NFa96WUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Replace <YOUR_NGROK_PUBLIC_URL> with your updated ngrok public URL\n",
        "url = \"<YOUR_NGROK_PUBLIC_URL>/train\"\n",
        "\n",
        "response = requests.post(url)\n",
        "\n",
        "print(response.json())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDNhLo_g6WSU",
        "outputId": "894c2a25-5c05-403e-eff1-17877be3eb35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     34.139.187.100:0 - \"POST /train HTTP/1.1\" 200 OK\n",
            "{'message': 'Model trained successfully', 'accuracy': 0.525, 'f1_score': 0.424, 'precision': 0.343, 'recall': 0.556}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@app.post(\"/predict\")\n",
        "async def predict_downtime(data: dict):\n",
        "    try:\n",
        "\n",
        "        required_fields = [\"Temperature\", \"Run_Time\"]\n",
        "        if not all(field in data for field in required_fields):\n",
        "            raise HTTPException(\n",
        "                status_code=400,\n",
        "                detail=f\"Missing required fields. Please provide: {required_fields}\"\n",
        "            )\n",
        "\n",
        "        input_data = pd.DataFrame([data])\n",
        "        input_data = input_data[required_fields]  #\n",
        "\n",
        "        input_scaled = scaler.transform(input_data)\n",
        "\n",
        "        prediction = model.predict(input_scaled)[0]\n",
        "        probability = model.predict_proba(input_scaled)[0][1]\n",
        "\n",
        "        return {\n",
        "            \"Downtime\": \"Yes\" if prediction == 1 else \"No\",\n",
        "            \"Confidence\": round(float(probability), 3)\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Prediction error: {str(e)}\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))"
      ],
      "metadata": {
        "id": "VDuo3bOi6WQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = {\n",
        "    \"Temperature\": 75.5,\n",
        "    \"Run_Time\": 500\n",
        "}\n",
        "\n",
        "response = requests.post(\n",
        "    \"<YOUR_NGROK_PUBLIC_URL>/predict\",\n",
        "    json=test_data\n",
        ")\n",
        "print(response.json())"
      ],
      "metadata": {
        "id": "__dWJoFo6WNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "588998f8-b53d-47ed-fc38-2666ee2e395d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     34.139.187.100:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "{'Downtime': 'Yes', 'Confidence': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XAv2bhKz6WK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aSGkrzBI6WGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hnjfWoCg5550"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}